{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b61a3-92eb-4891-90ee-1d10607b05ad",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336d784-65c2-4a11-8489-b445b1fad177",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gemini-2.0-flash\"\n",
    "else:\n",
    "    llm_model = \"ggemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84e441b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a09c35",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n  Â I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92dff22",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943237a7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(temperature=0.9, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdcdb42d",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7abc20b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/h7x3gp7x57n7kz8n91yjhw6w0000gn/T/ipykernel_49219/1305865249.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad44d1fb",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/h7x3gp7x57n7kz8n91yjhw6w0000gn/T/ipykernel_49219/550859008.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(product)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here are some name ideas, categorized for different styles and focuses:\\n\\n**Simple & Direct:**\\n\\n*   Queen Sheets Co.\\n*   Queen Size Sheets\\n*   The Queen Sheet Set\\n*   Queen Bed Linens\\n*   Perfect Queen Sheets\\n\\n**Focusing on Quality & Comfort:**\\n\\n*   Royal Comfort Sheets\\n*   Queen's Embrace Linens\\n*   Luxury Queen Sheets\\n*   Dream Weaver Sheets (for Queen Size)\\n*   Serene Sleep Queen\\n*   The Cozy Queen\\n\\n**Modern & Evocative:**\\n\\n*   Queen & Co.\\n*   Anya Sheets (if you want a personal, approachable feel)\\n*   The Queen Edit\\n*   Lunar Linens (evokes restful sleep)\\n*   Cloud Nine Queen\\n*   Ember Sheets (warm and inviting)\\n\\n**Unique & Playful:**\\n\\n*   Queen Bee Linens\\n*   The Queen's Chamber\\n*   Goodnight Queen\\n*   Queen's Bounty\\n*   Slumber Queen\\n\\n**Focusing on Material (if applicable):**\\n\\n*   Cotton Queen Sheets (if specializing in cotton)\\n*   Linen Queen (if specializing in linen)\\n*   Silk Queen Sheets (if specializing in silk)\\n*   Bamboo Queen (if specializing in Bamboo)\\n\\n**Tips for Choosing the Best Name:**\\n\\n*   **Target Audience:** Who are you trying to reach? (e.g., budget-conscious, luxury shoppers, eco-conscious consumers)\\n*   **Brand Personality:** What feeling do you want your brand to evoke? (e.g., trustworthy, sophisticated, playful)\\n*   **Availability:** Check if the name is available as a website domain and social media handle.\\n*   **Memorability:** Is the name easy to remember and pronounce?\\n*   **Relevance:** Does the name clearly communicate what you sell?\\n*   **Trademark Availability:** Ensure the name isn't already trademarked by another company in a similar industry.\\n\\n**Before finalizing, say the name out loud, get feedback from others, and do a thorough trademark search!**\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "febee243",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f31aa8a",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f5d5b76",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c1eb2c4",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78458efe",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mHere are some name ideas for a company that makes Queen Size Sheet Sets, broken down by category and with explanations:\n",
      "\n",
      "**Simple & Direct:**\n",
      "\n",
      "*   **Queen Sheets Co.** - Straightforward and easy to remember.\n",
      "*   **Queen Size Linens** - Clearly states what you offer.\n",
      "*   **Queen Comfort Sheets** - Focuses on the benefit of comfortable sheets.\n",
      "*   **Perfect Queen Sheets** - Implies quality and fit.\n",
      "*   **The Queen Sheet Set** - Simple, direct and emphasizes quality\n",
      "\n",
      "**Emphasis on Comfort/Luxury:**\n",
      "\n",
      "*   **Queen Dream Sheets** - Evokes a pleasant sleeping experience.\n",
      "*   **Silken Queen** - Implies luxurious, silky smooth sheets.\n",
      "*   **Queen Serenity Linens** - Focuses on relaxation and peace.\n",
      "*   **Queen Cloud Comfort** - Suggests soft and fluffy sheets.\n",
      "*   **The Regal Queen** - Luxury and quality\n",
      "\n",
      "**Modern & Catchy:**\n",
      "\n",
      "*   **Q.Sheets** - Short, modern, and memorable.\n",
      "*   **The Sheet Lab - Queen** - Implies innovation and quality testing.\n",
      "*   **Queenly Sleep** - Clever wordplay and focuses on quality sleep.\n",
      "*   **QueenWeave** - Highlights the fabric and weaving process.\n",
      "*   **Slumber Queen** - A modern take on sleep and royalty\n",
      "\n",
      "**Emphasis on Quality/Materials:**\n",
      "\n",
      "*   **Queen Cotton Co.** - If you specialize in cotton sheets.\n",
      "*   **Linen Queen** - If you specialize in linen sheets.\n",
      "*   **The Queen Thread** - Focuses on thread count and quality.\n",
      "*   **Artisan Queen Linens** - Implies handcrafted and high-quality.\n",
      "*   **Pure Queen Sheets** - Suggests natural and high-quality materials.\n",
      "\n",
      "**Creative & Unique:**\n",
      "\n",
      "*   **Queen's Rest** - Evokes a feeling of peaceful sleep.\n",
      "*   **Eightieth & Queen** - (If you want to establish a New York Vibe)\n",
      "*   **The Queen's Chamber** - Creates a sense of luxury and privacy.\n",
      "\n",
      "**Tips for Choosing the Best Name:**\n",
      "\n",
      "*   **Target Audience:**  Who are you trying to sell to?  Luxury buyers? Budget-conscious shoppers? The name should appeal to them.\n",
      "*   **Brand Identity:** What feeling do you want your brand to evoke? (Luxury, comfort, affordability, quality, eco-friendliness, etc.)\n",
      "*   **Availability:**  Check if the name and domain name (.com, .net, etc.) are available.  Also, check for trademark conflicts.\n",
      "*   **Memorability:** Is the name easy to remember and pronounce?\n",
      "*   **Relevance:** Does the name clearly relate to your product?\n",
      "*   **Scalability:** Does the name allow for future expansion into other sizes or types of bedding?\n",
      "\n",
      "**Before making a final decision, consider:**\n",
      "\n",
      "*   **Testing the name:** Get feedback from potential customers.\n",
      "*   **Checking online:** See if the name has any negative connotations or is already associated with another brand.\n",
      "\n",
      "Good luck!\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m**Queen Size Sheet Sets: Luxurious comfort meets quality materials. Experience a regal night's sleep with our perfectly crafted bedding.**\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"**Queen Size Sheet Sets: Luxurious comfort meets quality materials. Experience a regal night's sleep with our perfectly crafted bedding.**\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c129ef6",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "016187ac",
   "metadata": {
    "height": 217,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fb0730e",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6accf92d",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7a46121",
   "metadata": {
    "height": 217,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89603117",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"language\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51b04f45",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/h7x3gp7x57n7kz8n91yjhw6w0000gn/T/ipykernel_49219/1992003631.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_chain(review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
       " 'English_Review': \"I find the taste mediocre. The foam doesn't hold, it's strange. I buy the same ones in stores and the taste is much better...\\nOld batch or counterfeit!?\",\n",
       " 'summary': \"This reviewer found the product's taste mediocre and the foam subpar, suggesting it might be an old batch or counterfeit compared to store-bought versions.\",\n",
       " 'language': 'The review is in **French**.',\n",
       " 'followup_message': \"Okay, here are a few follow-up responses to the French summary, ranging from empathetic to slightly confrontational, depending on the tone you want to convey:\\n\\n**Option 1: Empathetic and seeking more information (polite):**\\n\\n> Merci pour votre commentaire. Nous sommes dÃ©solÃ©s d'apprendre que votre expÃ©rience n'a pas Ã©tÃ© Ã  la hauteur de vos attentes.  Pourriez-vous nous indiquer la date de pÃ©remption du produit que vous avez reÃ§u ? Cela nous aiderait Ã  comprendre si le problÃ¨me est liÃ© Ã  un lot particulier.  Ãgalement, oÃ¹ avez-vous achetÃ© le produit ?  Nous prenons trÃ¨s au sÃ©rieux les questions de qualitÃ© et d'authenticitÃ© et souhaitons y remÃ©dier au plus vite.\\n\\n**(Translation: Thank you for your comment. We are sorry to hear that your experience did not meet your expectations. Could you please tell us the expiration date of the product you received? This would help us understand if the problem is related to a particular batch. Also, where did you buy the product? We take quality and authenticity issues very seriously and want to remedy them as soon as possible.)**\\n\\n**Option 2:  More direct, focusing on verification (slightly more assertive):**\\n\\n> Nous vous remercions pour votre avis. Nous sommes surpris par votre commentaire concernant le goÃ»t et la mousse.  Pourriez-vous nous fournir plus d'informations sur l'endroit oÃ¹ vous avez achetÃ© ce produit, ainsi que le numÃ©ro de lot indiquÃ© sur l'emballage ? Cela nous permettra de vÃ©rifier l'authenticitÃ© du produit et de retracer son origine.\\n\\n**(Translation: Thank you for your review. We are surprised by your comment regarding the taste and the foam. Could you please provide us with more information about where you purchased this product, as well as the lot number indicated on the packaging? This will allow us to verify the authenticity of the product and trace its origin.)**\\n\\n**Option 3:  Acknowledging the issue and offering a solution (customer service oriented):**\\n\\n> Nous vous remercions d'avoir partagÃ© votre expÃ©rience. Nous sommes navrÃ©s d'apprendre que le goÃ»t et la mousse ne vous ont pas satisfait. Nous prenons vos remarques trÃ¨s au sÃ©rieux. Afin de nous excuser pour ce dÃ©sagrÃ©ment, nous vous proposons de vous renvoyer un autre produit ou de vous rembourser votre achat. Merci de nous contacter directement pour que nous puissions trouver une solution ensemble.\\n\\n**(Translation: Thank you for sharing your experience. We are sorry to hear that the taste and the foam did not satisfy you. We take your comments very seriously. In order to apologize for this inconvenience, we offer to send you another product or to refund your purchase. Please contact us directly so we can find a solution together.)**\\n\\n**Option 4:  A more skeptical, but still professional, response (use with caution):**\\n\\n> Merci pour votre avis.  Nous sommes dÃ©solÃ©s que vous ayez eu une expÃ©rience nÃ©gative. Pourriez-vous nous indiquer l'endroit exact oÃ¹ vous avez achetÃ© ce produit ? Il est important pour nous de vÃ©rifier si l'achat a Ã©tÃ© effectuÃ© auprÃ¨s d'un revendeur agrÃ©Ã©. Nous sommes trÃ¨s vigilants quant Ã  la contrefaÃ§on et souhaitons comprendre ce qui s'est passÃ©.\\n\\n**(Translation: Thank you for your review. We are sorry you had a negative experience. Could you please tell us the exact location where you purchased this product? It is important for us to verify whether the purchase was made from an authorized reseller. We are very vigilant about counterfeiting and want to understand what happened.)**\\n\\n**Key Considerations when choosing a response:**\\n\\n*   **Your company's policy on negative reviews:** Some companies prefer to be very conciliatory, while others take a more defensive approach.\\n*   **The severity of the complaint:** If the reviewer seems genuinely disappointed rather than aggressively complaining, a more empathetic response is appropriate.\\n*   **Your ability to actually investigate the issue:** If you can't track lot numbers or reseller information, asking for it might be pointless.\\n*   **Protecting your brand's reputation:**  Always aim for a professional and respectful tone, even if you suspect the review is unfair.\\n\\nChoose the option that best fits your needs and situation. Good luck!\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ade83f4f",
   "metadata": {
    "height": 778,
    "tags": []
   },
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f590e9f",
   "metadata": {
    "height": 387,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b06fc8",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3f50bcc",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8eefec24",
   "metadata": {
    "height": 200,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f98018a",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2e2ba",
   "metadata": {
    "height": 506,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ \"DEFAULT\" or name of the prompt to use in {destinations}\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: The value of âdestinationâ MUST match one of \\\n",
    "the candidate prompts listed below.\\\n",
    "If âdestinationâ does not fit any of the specified prompts, set it to âDEFAULT.â\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1387109d",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fb7d560",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d86b2131",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Alright, let's talk about black body radiation.\\n\\nImagine an object that absorbs *all* electromagnetic radiation that hits it, regardless of frequency or angle. That's a black body â a perfect absorber. Now, because it's absorbing energy, it also has to emit energy to stay in thermal equilibrium (otherwise it would just keep heating up forever!).  The radiation it emits is what we call black body radiation.\\n\\nHere's the key: the spectrum of light emitted by a black body depends *only* on its temperature.  It doesn't matter what the black body is made of, its shape, or anything else.  Just the temperature.\\n\\nThink of it like this:\\n\\n*   **Hotter black bodies:** Emit more radiation overall, and the peak of their emission shifts towards shorter wavelengths (bluer light).\\n*   **Cooler black bodies:** Emit less radiation overall, and the peak of their emission shifts towards longer wavelengths (redder light).\\n\\nThis relationship is described mathematically by Planck's Law, which gives the intensity of radiation emitted at each wavelength for a given temperature.  Wien's Displacement Law tells you the wavelength at which the emission is maximum, and the Stefan-Boltzmann Law tells you the total power radiated per unit area.\\n\\n**In short:** Black body radiation is the thermal electromagnetic radiation emitted by a perfect absorber (and emitter) whose spectrum depends only on its temperature. It's a fundamental concept in physics and has been crucial in the development of quantum mechanics.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b717379",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, this is a classic! Let\\'s break it down, even though it seems simple:\\n\\n*   **Component 1: Understanding the \"+\" symbol** The \"+\" symbol represents addition. Addition is a fundamental arithmetic operation that combines two or more quantities to find their total.\\n\\n*   **Component 2: Understanding the number \"2\"** The number \"2\" represents a quantity of two. It could be two apples, two fingers, two anything!\\n\\n*   **Component 3: The operation** We are asked to combine a quantity of \"2\" with another quantity of \"2\".\\n\\n*   **Component 4: Performing the addition** If we start with two items and add two more, we can count the total number of items.\\n\\n*   **Component 5: The result** Counting two items and then counting two more results in a total of four items.\\n\\nTherefore, 2 + 2 = 4'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29e5be01",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Every cell in our body contains DNA because DNA is the **blueprint for life**. It holds the complete set of instructions needed to build and operate an organism. Here's a breakdown of why it's essential in every cell:\\n\\n*   **Genetic Information:** DNA contains the genetic code that determines all of our traits, from eye color to susceptibility to certain diseases. This information is crucial for the cell's function and survival.\\n\\n*   **Protein Synthesis:** DNA contains the instructions for making proteins. Proteins are the workhorses of the cell, carrying out a vast array of functions, including:\\n    *   **Enzymes:** Catalyzing biochemical reactions.\\n    *   **Structural components:** Providing shape and support.\\n    *   **Hormones:** Signaling molecules.\\n    *   **Antibodies:** Defending against pathogens.\\n\\n*   **Cellular Function:** DNA dictates how a cell should function, including its growth, division, and specialization. Different cells express different genes (sections of DNA) to perform their specific roles in the body. For example, a muscle cell expresses genes related to muscle contraction, while a nerve cell expresses genes related to transmitting electrical signals.\\n\\n*   **Replication and Inheritance:** DNA is capable of replicating itself, ensuring that each new cell receives a complete and accurate copy of the genetic information during cell division. This is essential for growth, repair, and reproduction.\\n\\n*   **Regulation:** DNA contains regulatory sequences that control when and where genes are expressed. This allows cells to respond to changes in their environment and coordinate their activities with other cells.\\n\\nIn essence, DNA is the master control molecule that governs all aspects of cellular life. Without it, cells would not be able to function, grow, divide, or carry out their specialized roles in the body.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f0121-cf7b-464d-bb3d-6357719188ed",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912633a1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6378a95",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfdce90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
